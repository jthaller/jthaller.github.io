---
title: "Weeks of October 11th"
date: '2020-10-11'
categories:
  - weekly
tags:
  - Statistics
  - NLP
---

*In progress*

## What I did

- Reviewed, practiced, and improved my skills with SQL
- Read some practice data science questions and answers

## What I learned

- The precision-recall trade-off (again)
  


$$
\text{Precision} = \frac{\text{\# of True Positives}}{\text{\# of True Positives + \# of False Positives}} 
= \frac{\text{True Positives}}{\text{Actual Positives}}

\\

\text{Recall} = \frac{\text{\# of True Positives}}{\text{\# of True Positives + \# of False Negatives}}
= \frac{\text{True Positives}}{\text{Predicted Positives}}
$$

- Think about precision as the percent of your prediction that are relevant. Recall is the percent of your predictions that are actually correct. For example, say you are classifying cats and dogs, and your classifier predicts all 20 pictures as cats. If, in reality, 10 are cats and 10 are dogs, then your precision for predicting cats is 50% but your recall for predicting cats is 100%.

$$
Precision = \frac{10 ~ cats}{10 + 10 ~ cats}
\\
Recall = \frac{\text{10 ~ cats}}{10 + 0 ~ cats}
$$

The tradeoff is that the more you recall, the more likely you are to make a mistake. High precision is important for things like search results where you want only relevant results. JSTOR, for example, has shitty precision and high recall, unless you really dig deep into the advanced search features.


## What I will do Next
