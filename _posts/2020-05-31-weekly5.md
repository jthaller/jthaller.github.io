---
title: "Week of May 30th"
date: '2020-05-30'
categories:
  - weekly
tags:
  - Statistics
---

## What I did

* Worked on the backprop post. I wrote the backprop section.
* Major updates to resume. Formed a new branch for my 1 page resume, specifically taylored to data science jobs.
* Read another chapter of the stats textbook

## What I learned

* With regards to the backprop post, I feel much more confident in how backprop works. It's not that I didn't understand it before, but more that I have a better understanding now. It's the difference of doing a physics problem and explaining a physics propblem. These posts are my Oxbridge-style tutorials.
* T-tests, a test statistic to compare two population means. Use a pooled t-test when the standard deviations of the samples are very similar. $$S_1$$ and $$S_2$$ are the STD of the respective samples. Only use pooled samples when the standard deviations are the same (or very close), the samples are independent (obviously).

$$
H_0 : \mu_1 - \mu_2 = 0 \\
\text{Pooled} \\
t = \frac{\bar{x_1} - \bar{x_2}}{S_p \sqrt{1/n_1 + 1/n_2}} \\
S_p = \sqrt{\frac{(n-1)s_1^2 + (n-2)s_2^2 }{n_1 + n_2 - 2}} \\
\text{Unpooled} \\
t = \frac{\bar{x_1} - \bar{x_2}}{\sqrt{s_1^2/n_1 + s_2^2/n_2}} \\
df = DOF = (\text{there's an exact formula, but its long. just pick the smaller of } n_1 - 1 \text{ and } n_2 - 1)
$$

This means that the confidence interval of (1-$$\alpha$$)% is:

$$
(\overline{x}_1 - \overline{x}_2) \pm t_{\alpha/2} \sqrt{\sigma_1^2/n_1 + \sigma_2^2/n_2}
$$

for a two tailed hypothesis test, where t is calculated from the degrees of freedom I mentioned above.

* If each population is normal (or sample size is large enough, i.e. the central limit theorem), then the sampling distribution of $$\bar{x_i}$$ is also normally distributed with mean $$\mu_i$$, **Standard Error** $$\frac{\sigma_i}{\sqrt{n_i}}$$ and **Estimated Standard Error** of $$\frac{s_i}{\sqrt{n_i}}$$. i is for sample 1 or 2.

*

## What I will do next

* I really need to start another Kaggle project.
