---
title: "Week of May 24th"
date: '2021-05-24'
categories:
  - weekly
tags:
- raise exception
---
<div style="text-align: justify">

## What I did
- Monday: Hurst exponent, RNN's, Hopfield Network, Boltzmann Machine, Deep Belief Network
- Tuesday: Wrote most of the $$g(r)$$ program on my trainride back from NYC.
- Wednesday: Found the error preventing my `multi-moment-gaussianator.py` from working. One of the files had two identical points, i.e. (energy_99, mu_99) = (energy_100, mu_100), and it was causing a divide by zero error in my mesh interpolation.
- Thursday: Neural Network day. I wrote lots of boiler plate code for determining the quality of fits and predictions, saving and loading models, etc. 
- Friday: Predicted the MSD's of particle averaged spectrum using the single hidden layer NN. Worked on finding new skewnorm parameters to create the MSD's in the range I want.
- Saturday: Wrote `nn_buddy.py` to take care of the repetitive ploating and loading functions and hide them in a notebook other than nn.`ipynb`. It's similar to when I wrote a dataloader class for pytorch, except this time it's much simpler - just a single, very messy function.
- Sunday: Data exploration and preparing a powerpoint to present my findings.

## What I learned 
- Monday: Hurst exponent = a measure of randomness. If $$H=0.5$$ the data is totally random and can't be predicted. Hopfield Network can learn patterns of training data and reconstruct it from partial data. I have a nice idea to train a deep belief network with EXAFS, then feed it a XANES and have it predict the EXAFS.
- Tuesday: `df.hist(columns=[])`
- Wednesday: Don't ignore warnings. Just because the code runs, if it throws a warning, it might not be doing what you think it is. My script was throwing a divide by zero warning, but it ran, it just caused one value in a csv file to be blank and I had a hard time tracing back the cause.
- Thursday: I almost forgot to scale my training labels to be from 0-1 using:
$$
z_i = \frac{x_i - \text{Min}(x)}{\text{Max}(x)-\text{Min}(x)}
$$
- Friday: I realized my skew-norm averaged training data is weighted with much higher MSD's than the true disordered (particle averaged) data.
- Saturday: How to write your own errors to raise. There's a few ways to do it, but this is what I chose for my plottin function:

```python
class NoRowException(Exception):
    # return "no row specified"
    def __init__(self, message="Error: No row specified to plot"):
        self.message = message
        super().__init__(self.message)


def plot_spectrum(dataset, row=None, label=None, title=''):
    if row is None:
        raise NoRowException
    else:
        # do the plotting
```

- Sunday: Skew-norm parameters that are different can actually produce identical MSD's and very different spectra. I either need to switch to gaussian or try and train the NN to predict the full skewnorm.

## What I will do next
- Reassess my averaging methodology.

</div>